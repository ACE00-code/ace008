# 技术点

l 熟悉Java编程基础知识，包括集合、线程、IO等

l 了解Java并发编程，包括java的各种锁机制、线程池机制、AQS、CAS、ThreadLocal等

l 熟悉JVM，包括内存模型、类加载机制、常见GC算法、垃圾回收器等

l 熟悉MySQL数据库，包括一些基本原理MVCC、事务及隔离级别、索引等

l 熟练使用Spring、SpringBoot、SpringMVC、MyBatis框架，了解IOC、AOP、自动装配、SpringMVC的执行流程等

l 熟悉Redis，包括数据持久化机制、淘汰策略、过期策略、集群模式等

l 了解RabbitMQ，kafka，包括架构模式、路由规则等

l 了解Docker，Jenkins，k8s 相关服务部署应用，了解CI/CD流程，了解Prometheus及Grafana

l 了解Nginx，包括基本功能、负载均衡策略等

l 了解Linux系统以及常用命令

l 了解AIGC、AI Agent、RAG、NER等相关人工智能技术



## redis

![【超级详细】一文搞懂redis的所有知识点](https://pic1.zhimg.com/v2-c44490ed9191750a0652401db9d9c3bd_720w.jpg?source=172ae18b)

1.  完全**基于内存操作**，省去磁盘I/O的消耗
2.  命令执行使⽤**单线程**，避免了线程切换和竞态产生的消耗
3.  基于**⾮阻塞的IO多路复⽤**机制（epoll）
4.  **C语⾔**实现，优化过的数据结构，基于⼏种基础的数据结构，redis做了⼤量的优化，性能极⾼（例如sds简单动态字符串，虚拟内存技术）
5.  kv存储，**跳表**（二分查找，以空间换时间，提高查找效率）



string类型：int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串），二进制安全，sds简单动态字符串



什么是I/O多路复用？

- I/O ：网络 I/O
- 多路 ：多个网络连接
- 复用：复用同一个线程。
- IO多路复用其实就是一种同步IO模型，它实现了一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；而没有文件句柄就绪时,就会阻塞应用程序，交出cpu。



**Redis的虚拟内存机制是啥呢？**

> 虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。

## mysql

### bufferPool



**Buffer Pool 一次只能允许一个线程来操作，一次只有一个线程来执行这一系列的操作，因为MySQL 为了保证数据的一致性，操作的时候必须缓存池加锁，一次只能有一个线程获取到锁**。



问：多个 Buffer Pool 实例所带来的问题思考    在多个线程访问不同的 Buffer Pool 那不同的线程加载的数据必然是在不同的 Buffer Pool 中，假设 A 线程加载数据页A到 Buffer Pool A 中，B 线程加载数据页B到 Buffer Pool  B 中，然后两个都执行完了，这个时候 C 线程来了，他到达的是 Buffer Pool B中，但是 C 要访问的数据是在 Buffer Pool A中的数据页上了，这个时候 C 还会去加载数据页A吗？，这种情况会发生吗？在不同的 Buffer Pool 缓存中会去缓存相同的数据页吗？ 

 答：多个 Buffer Pool 所带来的问题解答    这种情况很显然不会发生，既然不会发生，那 MySql 是如何解决这种问题的？其实前面已经提到过了，那就是 数据页缓存哈希表（看下图），里面存放的是表空间号+数据页号 = 缓存页地址，所以  MySQL 在加载数据所在的数据页的时候根据这一系列的映射关系判断数据页是否被加载，被加载到了那个缓存页中，所以 MySQL 能够精确的确定某个数据页是否被加载，被加载的到了哪个缓存页，绝不可能出现重复加载的情况。

![img](https://ask.qcloudimg.com/http-save/7948575/co1t9aegrm.png)



![img](https://ask.qcloudimg.com/http-save/7948575/kaoxpik1i0.png)

free链表    

用来存放空闲的缓存页的描述数据，如果某个缓存页被使用了，那么该缓存页对应的描述数据就会被从free链表中移除

flush链表    

被修改的脏数据都记录在 Flush 中，同时会有一个后台线程会不定时的将 Flush 中记录的描述数据对应的缓存页刷新到磁盘中，如果某个缓存页被刷新到磁盘中了，那么该缓存页对应的描述数据会从 Flush 中移除，同时也会从LRU链表中移除（因为该数据已经不在 Buffer Pool 中了，已经被刷入到磁盘，所以就也没必要记录在 LRU 链表中了），同时还会将该缓存页的描述数据添加到free链表中，因为该缓存页变得空闲了。 

LRU链表    

数据页被加载到 Buffer Pool 中的对应的缓存页后，同时会将缓存页对应的描述数据放到 LRU 链表的冷数据的头部，当在一定时间过后，冷数据区的数据被再次访问了，就会将其转移到热数据区链表的头部，如果被访问的数据就在热数据区，那么如果是在前25%就不会移动，如果在后75%仍然会将其转移到热数据区链表的头部



预读机制     

 MySQL 在从磁盘加载数据的的时候，会将数据页的相邻的其他的数据页也加载到缓存中。 

MySQL 为什么要这么做       

 因为根据经验和习惯，一般查询数据的时候往往还会查询该数据相邻前后的一些数据，有人可能会反问：一个数据页上面不是就会存在该条数据相邻的数据吗？这可不一定，某条数据可能很大，也可能这条数据是在数据页在头部，也可能是在数据页的尾部，所以 MySQL 为了提高效率，会将某个数据页的相邻的数据页也加载到缓存池中。

![img](https://ask.qcloudimg.com/http-save/7948575/f8syhothn9.png)







什么是chunk机制   

chunk是 MySQL 设计的一种机制，这种机制的原理是将 Buffer Pool 拆分一个一个大小相等的 chunk 块，每个 chunk 默认大小为 128M（可以通过参数innodb_buffer_pool_chunk_size 来调整大小），也就是说 Buffer Pool 是由一个个的chunk组成的     假设 Buffer Pool 大小是2GB，而一个chunk大小默认是128M，也就是说一个2GB大小的 Buffer Pool 里面由16个 chunk 组成，每个chunk中有自己的缓存页和描述数据，而 free 链表、flush 链表和 lru 链表是共享的

![img](https://ask.qcloudimg.com/http-save/7948575/y51nvjevsi.png)



## kafka

Kafka是一个分布式的基于发布/订阅模式的消息队列(Message Queue)，主要应用于大数据实时处理领域。**发布/订阅**:消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息 分为不同的类别，订阅者只接收感兴趣的消息。Kafka是一个开源的分布式事件流平台(Event Streaming Platform)，被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。


![image-20250608184628390](https://github.com/user-attachments/assets/3fafdf0f-58c8-46b4-af4c-13b72752988a)


**生产者（Producer）**：消息生产者，就是向 kafka broker 发消息的客户端，生产者程序通常持续不断地向一个或多个主题发送消息。

**消费者（Consumer）**：消息消费者，向 kafka broker 取消息的客户端，消费者就是订阅这些主题消息的客户端应用程序。

和生产者类似，消费者也能够同时订阅多个主题的消息。我们把生产者和消费者统称为客户端（Clients）。你可以同时运行多个生产者和消费者实例，这些实例会不断地向 Kafka 集群中的多个主题生产和消费消息。

**消费者组Consumer Group (CG)**：由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

**Broker** ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。

**主题（topic）** ：可以理解为一个队列，生产者和消费者面向的都是一个 topic;

**分区（Partition）**：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker(即服务器)上， 一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列;

**副本（Replica）**：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本， 一个 **leader** 和若干个 **follower**。

**leader**：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。

**follower**：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据 的同步。leader 发生故障时，某个 follower 会成为新的 follower

**副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。**

Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个**只能追加写（Append-only）消息**的物理文件。因为只能追加写入，故**避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段**。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的





# 项目经历

## 一,AI微信小程序

· 容器服务申请及部署，搭建网络链路



· 架构方案设计，包括dpu，rag接入



· prompt编写及测试优化



· 完成Deepseek-R1接入，提高模型输出质量



· 智能体相关功能开发，完成dify平台接入

· 完成数据实体识别，数据溯源等需求

· 完成数据湖数据管理，实体治理，接口标准化，提供模型预料进行数据训练

· 完成相关功能上线，如登录功能，整体对话流程，历史聊天管理，分享功能等等

 使用cursor独立完成后台配置管理系统，包括前后端代码开发











## 二,全球企业库系统

· 全部服务接入安全网关，打通网关配置，在网关上登记所有接口，配置接口权限，实现所有接口统一管理和接口访问监控

· job服务重构-基于schedule+lock定时任务方案替换成XXL-Job，统一管理定时任务，以及提高定时任务开发效率

· 使用kafka+Redis 缓解高并发业务对数据库造成的读写压力

> 企业（人物）浏览记录：
> redis zadd zrem zrank（zset有序集合（sorted set）） （score:时间戳 key:userID+type value:typeID,companyCode,personID  ）
>
> 1，新增浏览记录：redis zadd zcard（获取数量，zremrangeByRank达到限制 删除最旧一条数据） redis 随机过期（24+random(24)）
> 	kafka send(topic: add) 0bject(uid+type,id,time) 消费入库，同时删除旧数据（insert or update 避免出现多条相同记录）
> 2，删除一条浏览记录： redis zrem
> 	kafka send(topic: delete_one) 0bject(uid+type,id,time)  删库
> 3，删除所有浏览记录： redis del
> 	kafka send(topic: delete_all) 0bject(uid+type,id,time)  删库
> 4，查看： redis zrange null?DB:redis redis zadd  
>
> 消费失败策略：告警
> 消费不需要保证顺序性（指定分区，一个分区）（推荐多少实例设置多少分区）
> 消息不积压
> 消息丢失策略（本地消息表）
>
> kafka 配置：集群，3节点，topic(4 分区、3 副本)
> acks=all、retries=3
>
> 每天20万次请求:
> 集中在 9:00 到 18:00,平均 QPS（Queries per second）= 200,000 ÷ 32,400 ≈ 6.17 QPS
> 假设 30% 的请求集中在10 分钟以内的高峰期 :峰值 QPS ≈ 60,000 ÷ 600 = 100 QPS
> 数据库一般可以轻松支持 100 QPS，数据库连接池是默认的 20~50 条连接
>
> 希望接口更快响应，减少阻塞时间（如果处理逻辑允许异步），减少服务线程都在处理数据库请求（假如50个线程都在阻塞操作数据库，则没有其他线程执行业务逻辑）
> 数据库负载较高或响应缓慢（比如超过 100ms），写数据库的操作耗时 100ms 以上， 使用 Kafka 可以显著降低接口延迟
> 写多读少，写库异步化
> 降低数据库压力	
> 未来预计请求量会增加，目前正在做c端，b端用户 20万，每天 20万次调用，四个消费者，每天2.5万次，未来预计请求量上涨，Kafka 可扩展性强
>
> 终端百万级用户



> 推送：
> 9点定时任务创建执行任务（每天任务推送状态表创建记录），初始化转态，获取任务内容（推送用户清单，用户对应推送内容清单）
> 1，先把用户清单放入kafka topic队列（邮件推送，app推送）
> 2，消费消息，对单个用户进行消息推送，redis对（任务类型+用户ID）加锁，确保单个用户只消费一次，
> 	获取推送内容组装模板（获取失败时重试3次，推送任务状态表新增异常记录及原因，邮件告警），
> 	对推送内容列表遍历做推送展示（获取失败时重试3次，推送任务状态表新增异常记录及原因，邮件告警）
> 	结束后更新任务状态表
>
> 两张表：1，每天任务推送状态表（推送消息数量，推送执行时间，状态（未开始，执行中，已结束），类型（邮件推送，app推送），重试次数）   2，推送任务详情表（uid，任务类型，标题，类型（邮件推送，app推送），重试次数，状态（成功，失败））（针对单用户的推送列表推送状态）
>
> 
>
> 推送内容 取企业最新动态业务数据
> 推送目标：有企业收藏的用户，收藏的企业有动态更新
> 	先取收藏服务查所有有收藏企业的用户，放入topic中，消费时取有动态更新的最新十家公司，
> 	拉去动态内容，（缓存动态数据（收藏的一般是热门企业）），组装数据调用三方接口进行推送

· 服务器容器化，迁移部分核心服务至k8s，便于服务自动化管理及扩展，使用Grafana及Prometheus对服务进行监控及告警，接入服务日志可视化平台，便于日志统一管理及提高问题排查效率

· 服务多机房搭建部署，保证服务高可用

· 定期基于SonarQube代码质量管理平台进行团队内Code Review，提高代码质量

· 解决部分大数据量导出业务引发内存溢出问题，进行代码优化及JVM调优，提高导出数据量上限，降低导出所耗费时间

· java进程crash崩溃问题排查及解决，保障系统的稳定性

· 完成JDK升级至17，SpringBoot升级至3.2

 排查并解决系统中存在的内存泄漏和死锁问题，解决项目中存在的安全隐患

> 线程池内存（TransmittableThreadLocal+普通线程池）泄露：导出服务用户信息内存泄露，导致用户导出任务列表中出现了他人的导出记录
>
> 线程池死锁：线程池嵌套使用，异步导出时，后台定时任务间隔几秒从任务队列中拉去任务，执行任务（无法判断也不需要关心业务中的逻辑），例如线程数为2的线程池，同时来了两个导出任务，这两个任务又使用该线程池创建各自五个可同时进行的子业务任务，子任务会放到任务队列中，等待父线程释放线程，但父线程需要等待子任务执行完才能释放线程







## 三,gsp卖家平台

· 熟悉两个系统的功能及代码，包括平台技术栈学习

· 设计支持高并发接口，提供外围系统使用，支持限流、mq异步处理任务

> 日志记录的场景，对卖家查看订单时进行日志，使用mq异步进行，自产自销的一个场景

· 在用户查看财务等敏感数据时，基于AOP实现拦截器进行用户身份校验

> 对某些操作权限较敏感的场景进行用户权限校验，如涉及财务的一些操作，对用户进行校验（调用三方接口，如果（true）已经二次校验过，直接返回数据，没有（false）则需要弹窗进行验证码二次校验）

· 进行sql优化

> 慢sql分析，添加索引，历史技术债

· 优化项目中存在的死锁问题

> 批量消费外部的消息修改数据库记录时，两条消息的主键ID顺序相反，导致相互等待（代码不是我写的，刚好写这个的那位同学请假了，所以我去排查和解决问题，主要通过查看日志分析，日志告警发现：事物A修改ID为1和2两条记录，事物B修改ID为2和1两条记录，两个事物同时进行，造成相互死锁，其中一个事物更新失败，数据库会选择一个事务进行回滚，解决方案：ID排序）

· 排查Redis中存在的大key，并进行优化

> 大key拆分存储

· 参与项目故障演练，进行总结

>通过Apollo配置控制开关，1、验证短信平台服务不可用场景下，通过降级方案用户也能正常进入系统，短信平台系统故障，短信平台无法发送邮箱、手机验证码，开发切换后无需验证码可登录系统（联系短信平台刘慧峰关闭网关权限

· 参与其他日常需求开发与自测，包括各模块需求代码编写，如与外围系统客服系统、物流系统、财务系统、ERP等进行接口数据对接

>增删改查接口对接





# 工作经历



1，参与万得金融终端的开发与自测，主要负责全球企业数据模块相关功能开发，编写相关需求概要设计及详细设计文档，需求测试用例及代码单元测试；



2，负责AI赋能项目，结合人工智能从0搭建企业库AI小程序，做垂直领域人工智能项目，并落地上线；



3，参与项目从ToB到ToC的转型，提高日活用户量
